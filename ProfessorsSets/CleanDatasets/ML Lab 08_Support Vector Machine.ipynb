{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IRIS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collected by British biologist and statistician Ronald Fisher in 1936.\n",
    "- Commonly used for classification examples - predict the species of iris flower based on measurements.\n",
    "- It includes three iris species with 50 samples each as well as some properties about each flower. \n",
    "- One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n",
    "- The dataset consists of 150 samples of iris flowers, divided into 3 species with 50 samples each.\n",
    "- Species: Iris setosa, Iris versicolor, Iris virginica\n",
    "- Each sample has 4 numerical features: SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm\n",
    "- The target variable is the species of the iris flower, encoded as integers: Iris setosa (0), Iris versicolor (1), Iris virginica (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "\n",
    "# Load data with only two classes and two features \n",
    "iris = datasets.load_iris()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Linearly Separable Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only two classes (as third class is not linearly separable)\n",
    "# and two features (so we can plot the graph) \n",
    "features = iris.data[:100,:2] \n",
    "target = iris.target[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() \n",
    "features_standardized = scaler.fit_transform(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points and color using their class - state space diagram\n",
    "color = [\"black\" if c == 0 else \"lightgrey\" for c in target] \n",
    "plt.scatter(features_standardized[:,0], features_standardized[:,1], c=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Create support vector classifier \n",
    "svc = LinearSVC(C=1.0) \n",
    "# Train model \n",
    "model = svc.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperplane \n",
    "w = svc.coef_[0] \n",
    "a = -w[0] / w[1]  # w[0] and w[1] are associated weights of the two features\n",
    "xx = np.linspace(-2.5, 2.5) \n",
    "yy = a * xx - (svc.intercept_[0]) / w[1] \n",
    "\n",
    "# Plot the hyperplane \n",
    "plt.scatter(features_standardized[:,0], features_standardized[:,1], c=color)\n",
    "plt.plot(xx, yy) \n",
    "plt.axis(\"off\"), plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new observation \n",
    "new_observation = [[ -2, 3]] \n",
    "# Predict class of new observation \n",
    "svc.predict(new_observation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Linearly Inseparable Classes using Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Linearly Inseparable Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set randomization seed\n",
    "np.random.seed(0)  \n",
    "# Generate two features \n",
    "features_ = np.random.randn(200, 2) \n",
    "# Use a XOR gate to generate linearly inseparable classes \n",
    "target_xor = np.logical_xor(features_[:, 0] > 0, features_[:, 1] > 0) \n",
    "target_ = np.where(target_xor, 0, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "from sklearn.svm import SVC \n",
    "from mlxtend.plotting import plot_decision_regions \n",
    "# mlxtend: ML extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create support vector classifier with a linear kernel \n",
    "svc_linear = SVC(kernel=\"linear\", random_state=0, C=1) \n",
    "\n",
    "# Train model \n",
    "model_linear=svc_linear.fit(features_, target_)\n",
    "\n",
    "# Plot observations and hyperplane \n",
    "plot_decision_regions(features_, target_, clf=svc_linear) \n",
    "plt.axis(\"off\"), plt.show(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions \n",
    "target_pred_linear = model_linear.predict(features_) \n",
    "target_pred_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing results\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(target_,target_pred_linear)*100)+\"%\") \n",
    "print(confusion_matrix(target_,target_pred_linear))  \n",
    "target_names = ['class 0', 'class 1'] \n",
    "print(classification_report(target_,target_pred_linear, target_names=target_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a support vector machine with a radial basis function (RBF) kernel \n",
    "svc_rbf = SVC(kernel=\"rbf\", random_state=0, gamma=1, C=1) \n",
    "\n",
    "# Train the classifier \n",
    "model_svc=svc_rbf.fit(features_, target_) \n",
    "\n",
    "# Plot observations and hyperplane \n",
    "plot_decision_regions(features_, target_, clf=svc_rbf) \n",
    "plt.axis(\"off\"), plt.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data with only two classes, but all 4 features\n",
    "iris = datasets.load_iris() \n",
    "features = iris.data[:100,:] \n",
    "target = iris.target[:100] \n",
    "\n",
    "# Standardize features \n",
    "scaler = StandardScaler() \n",
    "features_standardized = scaler.fit_transform(features) \n",
    "\n",
    "# Create support vector classifier object \n",
    "svc_ = SVC(kernel=\"linear\", random_state=0) \n",
    "\n",
    "# Train classifier \n",
    "model_ = svc_.fit(features_standardized, target) \n",
    "\n",
    "# View support vectors \n",
    "model_.support_vectors_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taining SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Load data with only two features \n",
    "#boston = datasets.load_boston()  # removed from sklearn\n",
    "#features = boston.data[:,0:2] \n",
    "#target = boston.target \n",
    "\n",
    "#loading the dataset from the csv file\n",
    "boston=pd.read_csv('Boston_Dataset.csv')\n",
    "\n",
    "#Creating a dataframe for the features\n",
    "features_r=boston.drop(['PRICE'],axis=1)\n",
    "\n",
    "#Creating a series for the target\n",
    "target_r=boston['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR \n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(features_r,target_r,test_size=0.50,random_state=0) \n",
    "\n",
    "# Create decision tree classifier object \n",
    "regressor = SVR(kernel='linear') \n",
    "regressor.fit(X_train, Y_train) \n",
    "\n",
    "# Make predictions\n",
    "Y_pred_r = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding R-squared score\n",
    "regressor.score(features_r,target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
