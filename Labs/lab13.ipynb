{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbs9jEsXAwix"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y-1s2nI1Awiy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA1gJu0zAwi0"
      },
      "source": [
        "## Example 1: Building an Artificial Neural Network for Binary Classification on The Heart Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsIKwPZhAwi0"
      },
      "source": [
        "### The Heart Datset\n",
        "\n",
        "File name: 'D6_Heart_Dataset_2.csv'\n",
        "\n",
        "This dataset has been obtained from Kaggle.\n",
        "\n",
        "The dataset contains 303 observations with 13 features and 1 class label with 0 and 1 values.\n",
        "These features are discussed below:\n",
        "1. age: in years\n",
        "2. sex: (1 = male; 0 = female)\n",
        "3. cp: chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 4 = asymptomatic)\n",
        "4. trestbps: resting blood pressure, in mm Hg on admission to the hospital\n",
        "5. chol: serum cholestrol in mg/dl\n",
        "6. fbs: fasting blood sugar, 120 mg.dl (1 = true; 0 = false)\n",
        "7. restecg: restinng electrocardiographic results (values: 0,1,2)\n",
        "8. thalach: maximum heart ache achieved\n",
        "9. exang: exercise induced angina (1 = yes; 0 = no)\n",
        "10. oldpeak: ST depression induced by exercise relative to rest\n",
        "11. slope: the slope of the peak exercise ST segment\n",
        "12. ca: number of major vessels (0-3) coloured by flouroscopy\n",
        "13. thal: (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
        "14. target: the predicted attribute, diagnosis of heart disease (0 = fit; 1 = diseased)\n",
        "\n",
        "This is a binary classification problem.\n",
        "Does not contain any categorical data, the dataset is clean. sed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzztnVz8Awi0",
        "outputId": "16ae8206-c008-4331-ace1-b43b4c7b66a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>110</td>\n",
              "      <td>264</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>193</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "0     63    1   3       145   233    1        0      150      0      2.3   \n",
              "1     37    1   2       130   250    0        1      187      0      3.5   \n",
              "2     41    0   1       130   204    0        0      172      0      1.4   \n",
              "3     56    1   1       120   236    0        1      178      0      0.8   \n",
              "4     57    0   0       120   354    0        1      163      1      0.6   \n",
              "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
              "298   57    0   0       140   241    0        1      123      1      0.2   \n",
              "299   45    1   3       110   264    0        1      132      0      1.2   \n",
              "300   68    1   0       144   193    1        1      141      0      3.4   \n",
              "301   57    1   0       130   131    0        1      115      1      1.2   \n",
              "302   57    0   1       130   236    0        0      174      0      0.0   \n",
              "\n",
              "     slope  ca  thal  target  \n",
              "0        0   0     1       1  \n",
              "1        0   0     2       1  \n",
              "2        2   0     2       1  \n",
              "3        2   0     2       1  \n",
              "4        2   0     2       1  \n",
              "..     ...  ..   ...     ...  \n",
              "298      1   0     3       0  \n",
              "299      1   0     3       0  \n",
              "300      1   2     3       0  \n",
              "301      1   1     3       0  \n",
              "302      1   1     2       0  \n",
              "\n",
              "[303 rows x 14 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Reading the file into a dataframe\n",
        "PATH='C:/Users/maria/Dropbox/Machine Learning and Deep Learning/Machine Learning/Undergraduate/Lectures/Datasets and Notebooks' #laptop\n",
        "#PATH='C:/Users/admin/Dropbox/Machine Learning and Deep Learning/Machine Learning/Undergraduate/Lectures/Datasets and Notebooks'  #office\n",
        "data=pd.read_csv(f'{PATH}/D6_Heart_Dataset_2.csv')\n",
        "\n",
        "#Displaying the read contents\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCWRzCNfAwi1"
      },
      "outputs": [],
      "source": [
        "# separating predictors\n",
        "X_heart = data.drop(\"target\",axis=1)\n",
        "\n",
        "# separating target\n",
        "Y_heart = data[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4wLGqFtAwi1"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset\n",
        "X_heart_train,X_heart_test,Y_heart_train,Y_heart_test = train_test_split(X_heart,Y_heart,test_size=0.80,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zgS6K-4Awi1",
        "outputId": "7c1dac2b-ebac-4ac5-82e2-6b1a0a1c867b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60, 13)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_heart_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ILrjTtfAwi1"
      },
      "source": [
        "### Defining the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe9N9McRAwi2"
      },
      "source": [
        "- The Sequential class in Keras is used to create neural networks.\n",
        "- It is a linear stack of layers.\n",
        "- It allows addition of one layer at a time, and each layer has exactly one input tensor and one output tensor.\n",
        "- Each layer automatically receives the output of the previous one as its input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbKKGxNZAwi2",
        "outputId": "bb414d73-7665-4df1-8f18-dc188d1fd106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " m1_hidden1 (Dense)          (None, 16)                224       \n",
            "                                                                 \n",
            " m1_hidden2 (Dense)          (None, 16)                272       \n",
            "                                                                 \n",
            " m1_output (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "# Start neural network\n",
        "network1 = models.Sequential()\n",
        "# Adding input layer\n",
        "network1.add(layers.Input(shape=(13,)))\n",
        "# Adding fully connected layer with a ReLU activation function\n",
        "network1.add(layers.Dense(units=16, activation=\"relu\", name='m1_hidden1'))\n",
        "# Adding fully connected layer with a ReLU activation function\n",
        "network1.add(layers.Dense(units=16, activation=\"relu\",name='m1_hidden2'))\n",
        "# Adding fully connected layer with a sigmoid activation function\n",
        "network1.add(layers.Dense(units=1, activation=\"sigmoid\",name='m1_output'))\n",
        "\n",
        "network1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKra_CPtAwi2",
        "outputId": "d34719b9-ec3c-4c12-846c-3d1cc14c155a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " m1_hidden1 (Dense)          (None, 16)                224       \n",
            "                                                                 \n",
            " m1_hidden2 (Dense)          (None, 16)                272       \n",
            "                                                                 \n",
            " m1_output (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Alternate definition\n",
        "network1 = models.Sequential([layers.Input(shape=(13,)),\n",
        "                              layers.Dense(units=16, activation=\"relu\", name='m1_hidden1'),\n",
        "                              layers.Dense(units=16, activation=\"relu\",name='m1_hidden2'),\n",
        "                              layers.Dense(units=1, activation=\"sigmoid\",name='m1_output'),\n",
        "                             ])\n",
        "network1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlyEtPMFAwi2"
      },
      "source": [
        "### Compiling the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNUyKtsrAwi2"
      },
      "outputs": [],
      "source": [
        "network1.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"rmsprop\",\n",
        "                 metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoOxDiJQAwi2"
      },
      "source": [
        "### Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAJYiFzUAwi3"
      },
      "outputs": [],
      "source": [
        "#Setting some hyperparameters\n",
        "batch_size = 5\n",
        "nr_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43km_bB3Awi3",
        "outputId": "7f6f9f9d-2117-4aaa-a0d8-d65062b0b8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 4.27 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history1=network1.fit(X_heart_train, Y_heart_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=nr_epochs, verbose=0,\n",
        "                      validation_data=(X_heart_test,Y_heart_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY5cRlEyAwi3"
      },
      "source": [
        "### Plotting the Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIgrh0PUAwi3",
        "outputId": "fdafa672-9e39-4423-bf81-618cde56112b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Plotting the learning curves for train and test accuracy\n",
        "plt.plot(history1.history['accuracy'], label='Train')\n",
        "plt.plot(history1.history['val_accuracy'], label='Validation')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-gavHIiAwi3",
        "outputId": "aea99678-3e6e-42b0-a0bd-d3c43d897793"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Plotting the learning curves for train and test loss\n",
        "plt.plot(history1.history['loss'], label='Train')\n",
        "plt.plot(history1.history['val_loss'], label='Validation')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jHJIZ8sAwi3"
      },
      "source": [
        "### Evaluating the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sxVi-QuAwi3",
        "outputId": "b039ff61-eca9-4902-afec-7c1569127080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.7078\n",
            "Test loss is 0.715\n",
            "Test accuracy is 70.8%\n"
          ]
        }
      ],
      "source": [
        "test_loss1, test_accuracy1 = network1.evaluate(X_heart_test, Y_heart_test)\n",
        "print(f'Test loss is {test_loss1:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy1:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rZ-75gmAwi4"
      },
      "source": [
        "## Example 2: Building an Artificial Neural Network for Multiclass Classification on The Reuters Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rjWCQOlAwi4"
      },
      "source": [
        "### The Reuters Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTp-OhEtAwi4"
      },
      "source": [
        "- The Reuters dataset in Keras is a classic benchmark for multiclass text classification.\n",
        "- It contains thousands of newswires (short news reports) from Reuters, labeled over 46 different topics.\n",
        "\n",
        "- Key Features:\n",
        "  - Dataset: Reuters newswires (1986 Reuters dataset)\n",
        "  - Number of classes: 46 distinct topics (e.g., politics, economics, markets)\n",
        "  - Total samples: ~11,228 newswires\n",
        "  - Input: Each newswire is encoded as a sequence of word indexes (integers).\n",
        "  - Output: A label (integer between 0 and 45) representing the topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-s4oBZAwi4"
      },
      "source": [
        "### Text Encoding of Reuters Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Np5wAx9Awi4"
      },
      "source": [
        "- Each sentence is encoded a a sequence of integers.\n",
        "- Each number corresponds to a specific word in a dictionary built from the entire corpus.\n",
        "- This is needed because:\n",
        "  - the neural networks can’t directly process text; they need numerical input,\n",
        "  - so integer encoding is a simple and effective way to convert words to numbers.\n",
        "- Different text encoding schemes are available.\n",
        "\n",
        "- In Keras, the Rueters dataset are encoded as follows:\n",
        "  - The dictionary assigns lower indexes to more frequent words (like \"the\", \"and\", \"market\").\n",
        "  - The word-to-index mapping is consistent across the dataset, but not directly human-readable.\n",
        "  - Allow easy preprocessing (like truncating or padding to a fixed length).\n",
        "  - For example:\n",
        "    - Sentence: \"The stock market surged today due to...\"\n",
        "    - Encoding: [1, 447, 43, 103 19, 2 ...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YRPwRUPAwi4"
      },
      "source": [
        "### Loading and Exploring the Reuters Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgo_imV4Awi4"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "# Set the number of features\n",
        "number_of_features = 5000\n",
        "\n",
        "# Load features (word indices) and target data\n",
        "(X_reuters_train, Y_reuters_train), (X_reuters_test, Y_reuters_test) = reuters.load_data(num_words=number_of_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMmn-geBAwi4",
        "outputId": "0f099aa2-a191-4597-e828-cd8e342c7faf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_reuters_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA5rfLmMAwi5",
        "outputId": "0a596e47-86ca-4650-cd5d-2b0fd3535611"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),\n",
              "       list([1, 3267, 699, 3434, 2295, 56, 2, 2, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]),\n",
              "       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]),\n",
              "       ...,\n",
              "       list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 2, 2, 2, 699, 2, 2, 2, 699, 244, 2, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 2, 7, 4, 2, 654, 5, 2, 2, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]),\n",
              "       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 2, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 2, 43, 359, 5, 4, 326, 753, 364, 17, 12]),\n",
              "       list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 2, 2, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 2, 1688, 340, 7, 194, 2, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 2, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 2, 2, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 2, 114, 2, 1752, 7, 4, 113, 17, 12])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_reuters_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBOsY_CNAwi5",
        "outputId": "163006a7-cca2-4341-89be-775037d3b686"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3,  4,  3, ..., 25,  3, 25], dtype=int64)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_reuters_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yThoi-TAwi5",
        "outputId": "2b2f9af5-082d-4b26-b75a-7bceb5552d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newswire:\n",
            "[1, 56, 2, 925, 149, 8, 16, 23, 931, 3875, 25, 116, 5, 165, 15, 10, 67, 13, 12, 12, 11, 2, 400, 81, 79, 457, 145, 22, 331, 28, 3026, 331, 61, 3609, 2097, 2, 79, 64, 85, 1863, 84, 22, 44, 2, 2275, 79, 296, 1384, 157, 2, 8, 16, 23, 3875, 4, 116, 6, 837, 2, 6, 3834, 31, 248, 1032, 2, 4, 1618, 5, 37, 38, 1639, 27, 358, 37, 38, 4716, 9, 6, 2, 4, 316, 9, 662, 5, 4, 765, 5, 291, 58, 60, 2660, 1067, 136, 4, 384, 292, 270, 120, 17, 12]\n",
            "Label:\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# Checking out a newswire\n",
        "newswire_no=6\n",
        "print('Newswire:')\n",
        "print(X_reuters_train[newswire_no])\n",
        "print('Label:')\n",
        "print(Y_reuters_train[newswire_no])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO1vNVajAwi5",
        "outputId": "0ad05530-f576-4a6e-aa08-77d756bb5520"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'? lt ? america ltd said it is again extending its offer of 13 dlrs a share for 3 3 mln ? development corp shares until today from yesterday at midnight yesterday 7 242 117 ? shares had been tendered up from 5 ? 165 shares 24 hours earlier ? said it is extending the offer to allow ? to comply with federal law ? the ownership of u s airlines by non u s citizens and to ? the terms and conditions of the letter of credit or bank guarantee required under the previously announced acquisition agreement reuter 3'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mapping the newswire back to the original words\n",
        "\n",
        "# Load the word index dictionary (word → integer)\n",
        "word_index = reuters.get_word_index()\n",
        "\n",
        "# Reversing word index to map integer indexes to their respective words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Decoding the review, mapping integer indices to words\n",
        "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in X_reuters_train[newswire_no]])\n",
        "\n",
        "decoded_review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz9J-WZHAwi5"
      },
      "source": [
        "### Preprocessing Reuters Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltH3f50wAwi5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Convert feature data to a one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "X_reuters_train_ = tokenizer.sequences_to_matrix(X_reuters_train, mode=\"binary\")\n",
        "X_reuters_test_ = tokenizer.sequences_to_matrix(X_reuters_test,mode=\"binary\")\n",
        "\n",
        "# One-hot encode target vector to create a target matrix\n",
        "Y_reuters_train_ = to_categorical(Y_reuters_train)\n",
        "Y_reuters_test_ = to_categorical(Y_reuters_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjE2US6BAwi5"
      },
      "source": [
        "### Defining the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v6-3MY4Awi6",
        "outputId": "cf13831f-ae15-4fd7-979c-16d4f8b366e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               500100    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 46)                4646      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 514,846\n",
            "Trainable params: 514,846\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "network2 = models.Sequential()\n",
        "network2.add(layers.Input(shape=(number_of_features,)))\n",
        "network2.add(layers.Dense(units=100,activation=\"relu\"))\n",
        "network2.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2.add(layers.Dense(units=46, activation=\"softmax\"))\n",
        "\n",
        "network2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTvEbWyvAwi6"
      },
      "source": [
        "### Compiling the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzRTV4giAwi6"
      },
      "outputs": [],
      "source": [
        "network2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"rmsprop\",\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDkEGGs1Awi6"
      },
      "source": [
        "### Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv69Hh2HAwi6",
        "outputId": "0d499682-4a79-48c4-b4e8-755efaebbd05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 15.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history2 = network2.fit(X_reuters_train_,\n",
        "                      Y_reuters_train_,\n",
        "                      epochs=20,\n",
        "                      verbose=0,\n",
        "                      batch_size=100,\n",
        "                      validation_data=(X_reuters_test_, Y_reuters_test_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNP-PJAyAwi6"
      },
      "source": [
        "### Evaluating the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8brtV6ZAwi7",
        "outputId": "5d136cd3-2cd1-4403-afc6-cca5807d2d25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 2ms/step - loss: 1.5745 - accuracy: 0.7818\n",
            "Test loss is 1.57\n",
            "Test accuracy is 78.2%\n"
          ]
        }
      ],
      "source": [
        "test_loss2, test_accuracy2 = network2.evaluate(X_reuters_test_, Y_reuters_test_)\n",
        "print(f'Test loss is {test_loss2:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy2:0.1%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSj7csoAAwi7",
        "outputId": "809afa28-85b8-4e60-9838-bb92fd370456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "281/281 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9676\n",
            "Train loss is 0.0673\n",
            "Train accuracy is 96.8%\n"
          ]
        }
      ],
      "source": [
        "train_loss2, train_accuracy2 = network2.evaluate(X_reuters_train_, Y_reuters_train_)\n",
        "print(f'Train loss is {train_loss2:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Madkt9-QAwi7"
      },
      "source": [
        "### Reducing Overfitting with Weight Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhM45mU_Awi7",
        "outputId": "f3fc4c10-dc18-49f7-b244-bb6bee40cef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 2ms/step - loss: 1.2594 - accuracy: 0.7578\n",
            "Test loss is 1.26\n",
            "Test accuracy is 75.8%\n",
            "281/281 [==============================] - 1s 2ms/step - loss: 0.9656 - accuracy: 0.8386\n",
            "Train loss is 0.966\n",
            "Train accuracy is 83.9%\n"
          ]
        }
      ],
      "source": [
        "from keras import regularizers\n",
        "\n",
        "# Defining network architecture\n",
        "network2a = models.Sequential()\n",
        "network2a.add(layers.Input(shape=(number_of_features,)))\n",
        "network2a.add(layers.Dense(units=100,activation=\"relu\",\n",
        "                          kernel_regularizer=regularizers.l2(0.01),))\n",
        "network2a.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2a.add(layers.Dense(units=46, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the Network\n",
        "network2a.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the network\n",
        "history2a = network2a.fit(X_reuters_train_, Y_reuters_train_, epochs=3, verbose=0, batch_size=100,\n",
        "                      validation_data=(X_reuters_test_, Y_reuters_test_))\n",
        "\n",
        "# Evaluating the model\n",
        "test_loss2a, test_accuracy2a = network2a.evaluate(X_reuters_test_, Y_reuters_test_)\n",
        "print(f'Test loss is {test_loss2a:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy2a:0.1%}')\n",
        "train_loss2a, train_accuracy2a = network2a.evaluate(X_reuters_train_, Y_reuters_train_)\n",
        "print(f'Train loss is {train_loss2a:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2a:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfubQArpAwi7"
      },
      "source": [
        "### Reducing Overfitting with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7QxPTaVAwi7",
        "outputId": "065a685a-61eb-4d05-94df-baefc0228125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 2ms/step - loss: 0.9040 - accuracy: 0.7952\n",
            "Test loss is 0.904\n",
            "Test accuracy is 79.5%\n",
            "281/281 [==============================] - 1s 2ms/step - loss: 0.3805 - accuracy: 0.9159\n",
            "Train loss is 0.38\n",
            "Train accuracy is 91.6%\n"
          ]
        }
      ],
      "source": [
        "from keras import regularizers\n",
        "\n",
        "# Defining network architecture\n",
        "network2b = models.Sequential()\n",
        "network2b.add(layers.Input(shape=(number_of_features,)))\n",
        "network2b.add(layers.Dense(units=100,activation=\"relu\"))\n",
        "network2b.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2b.add(layers.Dropout(0.2))\n",
        "network2b.add(layers.Dense(units=46, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the Network\n",
        "network2b.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the network\n",
        "history2b = network2b.fit(X_reuters_train_, Y_reuters_train_, epochs=3, verbose=0, batch_size=100,\n",
        "                      validation_data=(X_reuters_test_, Y_reuters_test_))\n",
        "\n",
        "# Evaluating the model\n",
        "test_loss2b, test_accuracy2b = network2b.evaluate(X_reuters_test_, Y_reuters_test_)\n",
        "print(f'Test loss is {test_loss2b:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy2b:0.1%}')\n",
        "train_loss2b, train_accuracy2b = network2b.evaluate(X_reuters_train_, Y_reuters_train_)\n",
        "print(f'Train loss is {train_loss2b:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2b:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrrWjkirAwi7"
      },
      "source": [
        "### Reducing Overfitting with Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr_HCbGXAwi7",
        "outputId": "ecd51d6a-cec9-41fe-f269-810942634571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 2ms/step - loss: 0.8745 - accuracy: 0.8010\n",
            "Test loss is 0.904\n",
            "Test accuracy is 80.1%\n",
            "281/281 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.9316\n",
            "Train loss is 0.324\n",
            "Train accuracy is 93.2%\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Defining network architecture\n",
        "network2c = models.Sequential()\n",
        "network2c.add(layers.Input(shape=(number_of_features,)))\n",
        "network2c.add(layers.Dense(units=100,activation=\"relu\"))\n",
        "network2c.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2c.add(layers.Dense(units=46, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the Network\n",
        "network2c.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Set callback functions to early stop training and save the best model so far\n",
        "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2),\n",
        "             ModelCheckpoint(filepath=\"best_model.h5\", monitor=\"val_loss\", save_best_only=True)]\n",
        "# EarlyStopping stops training early if the model stops improving on the validation set.\n",
        "# If the validation loss doesn't improve for 2 consecutive epochs (patience), training is stopped.\n",
        "# ModelCheckpoint saves the model during training in an HDF5 format file called \"best_model.h5\".\n",
        "# Only saves the model if the validation loss improves (i.e., is lower than the previous best).\n",
        "\n",
        "# Training the network\n",
        "history2c = network2c.fit(X_reuters_train_, Y_reuters_train_, epochs=3, verbose=0, batch_size=100,\n",
        "                          callbacks=callbacks, # Early stopping\n",
        "                          validation_data=(X_reuters_test_, Y_reuters_test_))\n",
        "\n",
        "# Evaluating the model\n",
        "test_loss2c, test_accuracy2c = network2c.evaluate(X_reuters_test_, Y_reuters_test_)\n",
        "print(f'Test loss is {test_loss2b:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy2c:0.1%}')\n",
        "train_loss2c, train_accuracy2c = network2c.evaluate(X_reuters_train_, Y_reuters_train_)\n",
        "print(f'Train loss is {train_loss2c:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2c:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxPXSQs-Awi8"
      },
      "source": [
        "## Example 3: Training a Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBzOOJ23Awi8"
      },
      "source": [
        "### Generating Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQob2fgUAwi8"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate features matrix and target vector\n",
        "X_regress, Y_regress = make_regression(n_samples = 10000,\n",
        "                                   n_features = 3,\n",
        "                                   n_informative = 3,\n",
        "                                   n_targets = 1,\n",
        "                                   noise = 0.0,\n",
        "                                   random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dHPq8RMAwi8",
        "outputId": "28386075-415f-43be-db26-48933144a06d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.29876053, -0.09037128, -0.70380582],\n",
              "       [-0.47120835, -0.43288143, -0.06250804],\n",
              "       [-0.65258817,  2.00808597, -1.09589096],\n",
              "       ...,\n",
              "       [ 1.02504134, -2.02531562, -0.21716545],\n",
              "       [ 0.682429  , -0.87764821, -0.98026165],\n",
              "       [-1.37701857,  2.01124319, -0.23550331]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_regress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW6DArVSAwi8",
        "outputId": "e6cfca8d-3fd2-4c76-c70e-e1489a7434be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  52.30810863,  -78.98981018,   53.41970504, ..., -106.68269507,\n",
              "        -82.21946021,   49.21147926])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_regress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBh2hKIdAwi8"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset\n",
        "X_regress_train, X_regress_test, Y_regress_train, Y_regress_test = train_test_split(X_regress, Y_regress, test_size=0.33, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBJmJ0pAAwi8"
      },
      "source": [
        "### Defining the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gZg4yGRAwi8",
        "outputId": "0e02e8ac-2e18-497c-a855-602355accec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 32)                128       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,217\n",
            "Trainable params: 1,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "network3 = models.Sequential()\n",
        "network3.add(layers.Input(shape=(X_regress_train.shape[1],)))\n",
        "network3.add(layers.Dense(units=32, activation=\"relu\"))\n",
        "network3.add(layers.Dense(units=32, activation=\"relu\"))\n",
        "network3.add(layers.Dense(units=1))\n",
        "\n",
        "network3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbziovetAwi9"
      },
      "source": [
        "### Compiling the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G91CpWRdAwi9"
      },
      "outputs": [],
      "source": [
        "network3.compile(loss=\"mse\",\n",
        "                optimizer=\"RMSprop\",\n",
        "                metrics=[\"mse\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toianwLQAwi9"
      },
      "source": [
        "### Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8XXx4joAwi9",
        "outputId": "7ec32a1e-ae91-450f-d26e-cfe7a367c7a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 1.96 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history = network3.fit(X_regress_train,\n",
        "                      Y_regress_train,\n",
        "                      epochs=10,\n",
        "                      verbose=0,\n",
        "                      batch_size=100,\n",
        "                      validation_data=(X_regress_test, Y_regress_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT5oZ-4jAwi9"
      },
      "source": [
        "### Evaluating the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qEI1j80Awi9",
        "outputId": "5cb19242-cc1d-43d1-e3f5-2ea48a8e2eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104/104 [==============================] - 0s 1ms/step - loss: 245.5400 - mse: 245.5400\n",
            "Test loss is 2.46e+02\n",
            "Test MSE is 245.5399627685547\n"
          ]
        }
      ],
      "source": [
        "test_loss3, test_mse3 = network3.evaluate(X_regress_test, Y_regress_test)\n",
        "print(f'Test loss is {test_loss3:0.3}')\n",
        "print(f'Test MSE is {test_mse3}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y scikit-learn # to reolve dependency errors, we downgrade\n",
        "!pip install scikit-learn==1.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "e1uVCh8ZTgcD",
        "outputId": "4cdd5f1b-4aad-4d3b-9db6-50810eca0823"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.5.2\n",
            "Uninstalling scikit-learn-1.5.2:\n",
            "  Successfully uninstalled scikit-learn-1.5.2\n",
            "Collecting scikit-learn==1.3.1\n",
            "  Downloading scikit_learn-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.17.3 (from scikit-learn==1.3.1)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.1) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.1) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.1) (3.6.0)\n",
            "Downloading scikit_learn-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikeras 0.13.0 requires scikit-learn>=1.4.2, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.3.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              },
              "id": "af910fc4e567443c89c4d909f30f958b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX-C0LyLAwi9"
      },
      "source": [
        "## Example 4: Tuning Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNPK7AdIAwi9",
        "outputId": "e9197338-f835-4a7f-fd7b-2053d4d34399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6042 - loss: 0.6622\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.3522\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.2031\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1566\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1435\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5865 - loss: 0.6664\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3493\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1836\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9492 - loss: 0.1589\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1372\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5898 - loss: 0.6770\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8498 - loss: 0.3616\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.1784\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1487\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1327\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5769 - loss: 0.6718\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8741 - loss: 0.3132\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.1835\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.1529\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1281\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5818 - loss: 0.6730\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.3720\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.1761\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.1553\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1335\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6052 - loss: 0.6465\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.2861\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1855\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1437\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1372\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5760 - loss: 0.6713\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3776\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2047\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.1721\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1509\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.6596\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.2962\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1829\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9484 - loss: 0.1504\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.1420\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.6664\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3698\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.1947\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1695\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1584\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.6599\n",
            "Epoch 2/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.3492\n",
            "Epoch 3/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1794\n",
            "Epoch 4/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1429\n",
            "Epoch 5/5\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1294\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5911 - loss: 0.6567\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3457\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1745\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1543\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1395\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1298\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.1259\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9624 - loss: 0.1184\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1118\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.1147\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5736 - loss: 0.6716\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3798\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.1991\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1548\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9553 - loss: 0.1353\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1295\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.1121\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1318\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.1248\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.1156\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5499 - loss: 0.6778\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3484\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.1922\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1586\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1441\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1302\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1237\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1073\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.1060\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.1071\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 0.6767\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.3687\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.1745\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1589\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1422\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1408\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.1372\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.1370\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.1210\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9705 - loss: 0.1133\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 0.6705\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3725\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1772\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.1571\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1340\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1373\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1294\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1133\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.1224\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.1157\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5570 - loss: 0.6876\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3577\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.1965\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1711\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1554\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.1288\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.1251\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.1167\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1321\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1181\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5710 - loss: 0.6762\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8126 - loss: 0.4036\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.2039\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1835\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1520\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1467\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.1215\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.1280\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9663 - loss: 0.1183\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.1121\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5748 - loss: 0.6793\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.4021\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2016\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.1581\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1415\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1165\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9586 - loss: 0.1416\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.1307\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.1138\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.1022\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5749 - loss: 0.6719\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4002\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.1891\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1523\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1336\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1379\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1359\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1254\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.1273\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1024\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.6610\n",
            "Epoch 2/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.3043\n",
            "Epoch 3/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1721\n",
            "Epoch 4/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1503\n",
            "Epoch 5/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1490\n",
            "Epoch 6/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1233\n",
            "Epoch 7/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.1103\n",
            "Epoch 8/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.1037\n",
            "Epoch 9/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1148\n",
            "Epoch 10/10\n",
            "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1185\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5613 - loss: 0.6857\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7817 - loss: 0.4640\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2312\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1717\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1494\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5447 - loss: 0.7009\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7520 - loss: 0.4979\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.2676\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1913\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1581\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 0.6941\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.4071\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2072\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.1546\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1401\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5456 - loss: 0.6960\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5272\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.2834\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.1840\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1478\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5898 - loss: 0.6634\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4103\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2094\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1676\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1459\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5457 - loss: 0.6881\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.5080\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2503\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.1778\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1559\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5796 - loss: 0.6676\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.4824\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.2491\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1713\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.1504\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5776 - loss: 0.6817\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8495 - loss: 0.3865\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2061\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1643\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1448\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5512 - loss: 0.6887\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4432\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2133\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.1673\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1548\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5713 - loss: 0.6841\n",
            "Epoch 2/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.5362\n",
            "Epoch 3/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.3356\n",
            "Epoch 4/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9316 - loss: 0.1941\n",
            "Epoch 5/5\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1607\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5666 - loss: 0.6982\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7915 - loss: 0.4521\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2272\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1655\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.1547\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1372\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1336\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.1219\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1284\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1170\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5835 - loss: 0.6685\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4533\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2425\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.1888\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1556\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.1325\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1301\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9621 - loss: 0.1299\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1254\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.1196\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6884\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.4988\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2723\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.1641\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1561\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1373\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1335\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1208\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1034\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9663 - loss: 0.1214\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5715 - loss: 0.6777\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7578 - loss: 0.4880\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.2591\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1786\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1646\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1291\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1324\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.1202\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.1176\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.1092\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5559 - loss: 0.6873\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8100 - loss: 0.4441\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2144\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1662\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1508\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1301\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1229\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1072\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1076\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0993\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 0.6703\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.4115\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2160\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9451 - loss: 0.1613\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.1441\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1298\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9572 - loss: 0.1331\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.1244\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1131\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0947\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5468 - loss: 0.7106\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.4887\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2239\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.1652\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1449\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1381\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1332\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.1233\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1058\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.1092\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5778 - loss: 0.6895\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.4241\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2020\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.1591\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1429\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1369\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1208\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9592 - loss: 0.1336\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1118\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1050\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5861 - loss: 0.6827\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7903 - loss: 0.4457\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2275\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1715\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1563\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1382\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9633 - loss: 0.1198\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.1105\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.1179\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9636 - loss: 0.1207\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5693 - loss: 0.6857\n",
            "Epoch 2/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8179 - loss: 0.4187\n",
            "Epoch 3/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2050\n",
            "Epoch 4/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1554\n",
            "Epoch 5/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1463\n",
            "Epoch 6/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9618 - loss: 0.1228\n",
            "Epoch 7/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1182\n",
            "Epoch 8/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.1129\n",
            "Epoch 9/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.1058\n",
            "Epoch 10/10\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.1135\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5147 - loss: 0.7235\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 0.6655\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 0.6295\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.5672\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.4873\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4961 - loss: 0.7292\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5680 - loss: 0.6808\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 0.6597\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6636 - loss: 0.6207\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7039 - loss: 0.5802\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.7270\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6134 - loss: 0.6547\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6689 - loss: 0.6054\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.5430\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7841 - loss: 0.4732\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4880 - loss: 0.7423\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5920 - loss: 0.6735\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6449 - loss: 0.6379\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.5867\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5391\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5244 - loss: 0.7296\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5811 - loss: 0.6730\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 0.6418\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.5911\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7234 - loss: 0.5388\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4993 - loss: 0.7331\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5973 - loss: 0.6647\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6611 - loss: 0.6186\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6944 - loss: 0.5633\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7556 - loss: 0.5003\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.7722\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6073 - loss: 0.6562\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.5950\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.5160\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4280\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: 0.7210\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5758 - loss: 0.6771\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6336 - loss: 0.6433\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6792 - loss: 0.5995\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5406\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4951 - loss: 0.7326\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5736 - loss: 0.6784\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6243 - loss: 0.6492\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 0.6006\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.5295\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5098 - loss: 0.7146\n",
            "Epoch 2/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5782 - loss: 0.6738\n",
            "Epoch 3/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6364 - loss: 0.6410\n",
            "Epoch 4/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 0.6031\n",
            "Epoch 5/5\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.5613\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4990 - loss: 0.7189\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5801 - loss: 0.6750\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6351 - loss: 0.6434\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.6007\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7256 - loss: 0.5499\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7630 - loss: 0.4973\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.4401\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3669\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3028\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2429\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5522 - loss: 0.6925\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6184 - loss: 0.6556\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6686 - loss: 0.6154\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 0.5631\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7609 - loss: 0.5118\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.4601\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.3797\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.3041\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2583\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2073\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5154 - loss: 0.7080\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5740 - loss: 0.6772\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6368 - loss: 0.6479\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6817 - loss: 0.6036\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5526\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7715 - loss: 0.4858\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.4158\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 0.3255\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.2579\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2108\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5120 - loss: 0.7151\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5727 - loss: 0.6759\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6305 - loss: 0.6385\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6943 - loss: 0.5935\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5415\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.4736\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3946\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.3127\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2624\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2182\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5063 - loss: 0.7270\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5910 - loss: 0.6687\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6454 - loss: 0.6327\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7080 - loss: 0.5712\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.5023\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.4205\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.3329\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2676\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2240\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1844\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.7108\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5824 - loss: 0.6720\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 0.6444\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.6053\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.5545\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.5019\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4393\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.3740\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.3050\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2478\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5034 - loss: 0.7685\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.6715\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6883 - loss: 0.6181\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.5408\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.4179\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3050\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2366\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1942\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.1788\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1601\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5257 - loss: 0.6986\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6023 - loss: 0.6630\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 0.6296\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.5881\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5473\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.5139\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.4652\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.4133\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3552\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.3013\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5303 - loss: 0.7302\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 0.6636\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6509 - loss: 0.6297\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 0.5847\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5342\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.4735\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.4012\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3288\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2574\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.2072\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5205 - loss: 0.7195\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5875 - loss: 0.6720\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6436 - loss: 0.6367\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6936 - loss: 0.5885\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7535 - loss: 0.5236\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4391\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3473\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.2728\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9235 - loss: 0.2140\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.1818\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/5\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5948 - loss: 0.6498\n",
            "Epoch 2/5\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2361\n",
            "Epoch 3/5\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1752\n",
            "Epoch 4/5\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1570\n",
            "Epoch 5/5\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1416\n",
            "CPU times: user 15min 59s, sys: 50.6 s, total: 16min 50s\n",
            "Wall time: 19min 34s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 5, 'epochs': 5, 'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# pip install scikeras\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Number of features\n",
        "number_of_features = 100\n",
        "# Generate features matrix and target vector\n",
        "features, target = make_classification(n_samples = 10000,\n",
        "                                       n_features = number_of_features,\n",
        "                                       n_informative = 3,\n",
        "                                       n_redundant = 0,\n",
        "                                       n_classes = 2,\n",
        "                                       weights = [.5, .5],\n",
        "                                       random_state = 0)\n",
        "\n",
        "# Create function returning a compiled network\n",
        "def create_network(optimizer=\"rmsprop\"):\n",
        "    # Defining the neural network\n",
        "    network = models.Sequential()\n",
        "    network.add(layers.Input(shape=(number_of_features,)))\n",
        "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
        "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
        "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    # Compile neural network\n",
        "    network.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    # Return compiled network\n",
        "    return network\n",
        "\n",
        "# Wrap Keras model so it can be used by scikit-learn\n",
        "neural_network = KerasClassifier(model=create_network, verbose=1)\n",
        "\n",
        "# Create hyperparameter space\n",
        "epochs = [5, 10]\n",
        "batches = [5, 10, 100]\n",
        "optimizers = [\"rmsprop\", \"adam\"]\n",
        "\n",
        "# Create hyperparameter options\n",
        "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
        "\n",
        "# Create grid search\n",
        "grid = GridSearchCV(estimator=neural_network,\n",
        "                    param_grid=hyperparameters)\n",
        "\n",
        "# Fit grid search\n",
        "grid_result = grid.fit(features, target)\n",
        "\n",
        "# View hyperparameters of best neural network\n",
        "grid_result.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp4vzgZtAwi-"
      },
      "source": [
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNBqWtWIAwi-"
      },
      "source": [
        "- IMBd (Internet Movie Database) is an online database of information related to films, television series, podcasts, home videos, video games, and streaming content online – including cast, production crew and personal biographies, plot summaries, trivia, ratings, and fan and critical reviews.\n",
        "- Keras has a built-in IMDb movie reviews data set.\n",
        "- This is a dataset of 50,000 movies reviews from IMDB, labeled by sentiment (positive/negative).\n",
        "- They are split into 25,000 for training and 25,000 for testing, each set consisting of 50% negative and 50% positive reviews.\n",
        "- Reviews have been tokenized, and each review is encoded as a list of word indexes (integers).\n",
        "- For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
        "- Indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\" / out-of-vocabulary (oov)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2JQ7L5VTAwi-"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "# Set the number of features\n",
        "number_of_features = 10000\n",
        "\n",
        "# Load features (word indices) and target data\n",
        "(X_imdb_train, Y_imdb_train), (X_imdb_test, Y_imdb_test) = keras.datasets.imdb.load_data(\n",
        "    path=\"imdb.npz\",\n",
        "    num_words=number_of_features,\n",
        "    skip_top=0,\n",
        "    maxlen=None,\n",
        "    seed=113,\n",
        "    start_char=1,\n",
        "    oov_char=2,\n",
        "    index_from=23, # to eliminate first 20 words as well\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "outputId": "f2f93e03-3d98-44f0-d3ee-9672f8fd8ee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ExyoZOCDIin"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(Y_imdb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "outputId": "8c9d4e22-29b3-4900-a20a-045f9750dd8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G70I0baLDIio"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 34, 42, 36, 63, 550, 993, 1642, 1405, 85, 478, 4488, 86, 3961, 24, 193, 56, 276, 25, 45, 120, 63, 858, 132, 70, 690, 2, 29, 55, 500, 304, 25, 170, 24, 192, 132, 187, 2, 356, 405, 59, 24, 192, 4556, 1131, 37, 566, 58, 33, 467, 24, 212, 70, 36, 26, 167, 2045, 39, 34, 42, 24, 1940, 4633, 489, 24, 42, 91, 107, 32, 36, 63, 550, 58, 96, 35, 33, 1267, 24, 42, 37, 535, 37, 32, 36, 646, 38, 2, 25, 82, 406, 32, 28, 336, 28, 126, 25, 24, 2243, 5264, 36, 500, 86, 3805, 53, 24, 150, 32, 36, 58, 639, 25, 45, 144, 71, 56, 155, 68, 45, 1435, 53, 26, 42, 32, 235, 48, 97, 72, 25, 34, 427, 36, 102, 2, 28, 24, 127, 137, 5972, 35, 276, 24, 2, 27, 3786, 25, 743, 56, 91, 63, 550, 496, 46, 420, 337, 66, 27, 24, 2, 1049, 33, 124, 108, 24, 401, 35, 317, 118, 52, 2091, 76, 46, 161, 26, 214, 7506, 38, 24, 246, 42, 41, 154, 496, 46, 500, 25, 164, 50, 5555, 38, 71, 56, 48, 244, 112, 45, 124, 24, 246, 85, 36, 58, 1354, 108, 32, 36, 303, 25, 36, 4492, 133, 123, 52, 35, 36, 5365, 39, 198, 52]),\n",
              "       list([1, 214, 1173, 214, 8275, 98, 248, 25, 26, 1483, 4389, 5032, 154, 46, 24, 735, 28, 138, 1654, 34, 414, 40, 33, 139, 974, 209, 122, 25, 227, 130, 3123, 41, 34, 89, 208, 28, 50, 43, 27, 24, 269, 146, 113, 24, 134, 29, 2320, 1543, 25, 667, 24, 136, 29, 55, 8183, 24, 249, 29, 360, 1342, 24, 138, 29, 24, 150, 4921, 39, 24, 1022, 25, 109, 49, 972, 66, 57, 24, 475, 29, 65, 63, 58, 1563, 1925, 418, 24, 1669, 46, 6873, 25, 183, 31, 3235, 2, 24, 1173, 29, 214, 795, 27, 8275, 2, 369, 2657, 168, 625, 2, 8023, 35, 143, 145, 88, 2, 6873, 35, 369, 185, 4382, 118, 25, 24, 248, 29, 63, 2, 1177, 35, 319, 140, 25, 140, 194, 31, 240, 195, 156, 70, 29, 4393, 248, 8275, 25, 2, 676, 265, 2370, 25, 24, 9857, 151, 172, 511, 38, 2, 52, 7484, 1232, 34, 29, 26, 391, 98, 42, 645, 84, 1402, 29, 28, 188, 165, 43, 24, 1710, 35, 36, 24, 1375, 25, 48, 26, 72, 174, 482, 53, 109, 98, 305, 36, 165, 115]),\n",
              "       list([1, 34, 67, 28, 50, 51, 27, 24, 269, 128, 27, 24, 5994, 74, 81, 389, 33, 91, 169, 34, 42, 132, 24, 2421, 331, 32, 36, 3731, 53, 95, 63, 1849, 316, 24, 106, 340, 55, 554, 39, 283, 4841, 1321, 24, 1893, 53, 109, 98, 32, 86, 36, 24, 380, 27, 24, 78, 336, 354, 31, 24, 1736, 63, 665, 682, 28, 277, 105, 1220, 62, 1248, 2598, 103, 88, 3932, 35, 56, 185, 1559, 298, 56, 89, 2, 800, 28, 126, 34, 6925, 1358, 38, 26, 42, 32, 235, 48, 630, 60, 26, 107, 346, 43, 2320, 41, 43, 42, 32, 292, 60, 77, 51, 31, 24, 42, 67, 26, 2327, 71, 29, 190, 43, 615, 136, 615, 1372, 33, 211, 99, 658, 109, 2, 34, 29, 28, 126, 627, 644, 55, 554, 26, 247, 27, 149, 133]),\n",
              "       ...,\n",
              "       list([1, 31, 26, 250, 265, 6421, 29, 26, 1245, 466, 2, 65, 2194, 104, 8342, 4027, 41, 24, 932, 104, 2, 345, 745, 154, 2, 1735, 104, 25, 56, 48, 77, 1119, 41, 28, 160, 28, 723, 25, 2, 104, 76, 38, 1664, 34, 29, 51, 27, 24, 9426, 1229, 2315, 2, 1028, 38, 26, 40, 227, 130, 583, 32, 28, 2921, 2, 28, 117, 26, 40, 73, 4787, 94, 24, 480, 384, 1293, 49, 290, 31, 980, 128, 65, 60, 49, 2981, 415, 31, 26, 4085, 520, 27, 2, 109, 384, 90, 49, 160, 24, 84, 4800, 31, 24, 2698, 46, 198, 24, 549, 463, 2, 25, 47, 730, 137, 2, 8143, 185, 67, 104, 57, 151, 838, 34, 615, 30, 30, 81, 1262, 1229, 30, 30, 308, 2280, 1722, 54, 2921, 2, 24, 85, 516, 24, 251, 27, 810, 25, 26, 340, 254, 2786, 254, 1139, 1594, 27, 516, 24, 159, 949, 2921, 2, 7770, 25, 4261, 38, 24, 8517, 2, 270, 31, 1838, 7581, 24, 4237, 5428, 767, 1135, 392, 1910, 1026, 561, 9323, 27, 24, 79, 2, 24, 3606, 2]),\n",
              "       list([1, 1466, 7099, 89, 92, 3325, 33, 630, 950, 28, 32, 602, 43, 25, 36, 504, 705, 74, 369, 31, 4140, 2979, 65, 78, 1486, 33, 217, 32, 36, 63, 43, 2, 25, 82, 50, 165, 422, 31, 4151, 71, 595, 52, 81, 389, 91, 86, 790, 32, 1074, 95, 120, 2218, 28, 24, 125, 57, 89, 167, 732, 95, 3563, 64, 277, 410, 25, 89, 283, 534, 125, 70, 306, 1834, 43, 24, 143, 33, 181, 60, 25, 441, 24, 136, 36, 917, 33, 2, 60, 339, 5892, 132, 6720, 31, 4823, 141, 45, 90, 3488, 24, 739, 3818, 33, 38, 51, 82, 60, 28, 7220, 24, 2, 27, 34, 143, 25, 962, 45, 28, 741, 32, 165, 25, 222, 32, 180, 600, 222, 32, 26, 72, 78, 2, 112, 421, 748, 32, 59, 34, 271, 28, 35, 271, 25, 2, 32, 58, 104, 100, 144, 32, 29, 43]),\n",
              "       list([1, 37, 26, 214, 357, 27, 24, 224, 42, 65, 274, 28, 126, 34, 143, 24, 2, 290, 2, 25, 2, 2, 752, 2118, 121, 425, 59, 34, 1054, 24, 1330, 29, 135, 70, 325, 32, 67, 24, 188, 25, 255, 27, 58, 131, 719, 122, 27, 24, 4059, 9265, 29, 44, 26, 98, 1119, 37, 2365, 2, 41, 47, 9705, 6159, 25, 2, 1623, 112, 1203, 24, 1330, 27, 24, 224, 62, 117, 110, 55, 241, 129, 49, 147, 47, 138, 28, 117, 32, 177, 41, 6809, 2, 29, 26, 86, 98, 1119, 24, 651, 1211, 25, 2662, 292, 211, 1090, 26, 7605, 28, 2217, 2, 2, 564, 25, 403, 1291, 868, 1488, 2, 517, 2, 28, 1617, 8798, 2, 41, 80, 47, 259, 29, 63, 8388, 229, 425, 30, 30, 32, 784, 60, 24, 268, 40, 32, 36, 25, 194, 1811, 92, 27, 71, 26, 1759, 42, 24, 224, 151, 29])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_imdb_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "outputId": "ad399e87-2ebe-419d-bfc7-c14755d952fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXmE2ULkDIio"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "Y_imdb_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "outputId": "a62f626c-ee47-4c72-892a-bcaff7a50a2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAS9DR1UDIio"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMDb:\n",
            "[1, 6760, 385, 1254, 25, 1176, 374, 31, 34, 5347, 6658, 27, 1036, 2, 5960, 376, 64, 24, 1369, 520, 766, 25, 220, 24, 4152, 31, 2, 9383, 1137, 1851, 7505, 25, 4851, 46, 26, 2, 4203, 37, 389, 57, 235, 1365, 163, 2, 25, 1858, 28, 1994, 35, 56, 139, 277, 105, 72, 506, 29, 26, 2, 8584, 83, 291, 26, 216, 116, 969, 4141, 24, 2, 27, 24, 2232, 2456, 839, 83, 67, 97, 7195, 200, 26, 247, 31, 114, 2514, 2, 33, 443, 24, 188, 27, 24, 42, 25, 109, 685, 91, 290, 76, 25, 33, 217, 32, 181, 5410, 119, 96, 43, 2, 27, 439, 685, 60, 111, 105, 128, 27, 24, 2104, 25, 4793, 101, 75, 72, 1921]\n",
            "Label:\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Checking out a newswire\n",
        "imdb=6\n",
        "print('IMDb:')\n",
        "print(X_imdb_train[imdb])\n",
        "print('Label:')\n",
        "print(Y_imdb_train[imdb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "outputId": "1f667779-9fc4-4a93-b65e-c66f7e56dd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "ztMxywTVDIip"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? serum came utterly you win video one by automatically anticipated his cute ? uniformly tell only not presence gave release you almost not consistently one ? relied depth nick 1955 you randomly out are ? dances who wonderful no feel ride funny ? you quiet have gags an up scenes ending characters me child he are ? adultery into year are come acting monster awake not ? his not rescue deaths brought into see make blamed between are rather one plot draw ? at mr not got his not or you character disappointed most worth much you at role all want deniro love way just ? his problem disappointed even many characters better his not failure you equivalent any we me manage'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Mapping the newswire back to the original words\n",
        "\n",
        "# Load the word index dictionary (word → integer)\n",
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Reversing word index to map integer indexes to their respective words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Decoding the review, mapping integer indices to words\n",
        "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in X_imdb_train[imdb]])\n",
        "\n",
        "decoded_review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UGjEen9DIip"
      },
      "source": [
        "### Preprocessing Reuters Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yCR3C2KRDIip"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Convert feature data to a one-hot encoded feature matrix\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "X_imdb_train_ = tokenizer.sequences_to_matrix(X_imdb_train, mode=\"binary\")\n",
        "X_imdb_test_ = tokenizer.sequences_to_matrix(X_imdb_test,mode=\"binary\")\n",
        "\n",
        "# One-hot encode target vector to create a target matrix\n",
        "Y_imdb_train_ = to_categorical(Y_imdb_train)\n",
        "Y_imdb_test_ = to_categorical(Y_imdb_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye-BgouTDIip"
      },
      "source": [
        "### Defining the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "outputId": "5a3d3477-ce12-42c5-a80f-0ce9135b4583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "H5cPgdFCDIip"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │     \u001b[38;5;34m1,000,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,010,402\u001b[0m (3.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,010,402</span> (3.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,010,402\u001b[0m (3.85 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,010,402</span> (3.85 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network2 = models.Sequential()\n",
        "network2.add(layers.Input(shape=(number_of_features,)))\n",
        "network2.add(layers.Dense(units=100,activation=\"relu\"))\n",
        "network2.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2.add(layers.Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "network2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqFtLbjtDIip"
      },
      "source": [
        "### Compiling the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cRtzxUSkDIip"
      },
      "outputs": [],
      "source": [
        "network2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"rmsprop\",\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTphjdpADIiq"
      },
      "source": [
        "### Training the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "outputId": "3545b300-623b-4abe-8e7b-9673dcfc5a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Get5qRDIiq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9548 - loss: 0.1261 - val_accuracy: 0.8743 - val_loss: 0.3453\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9751 - loss: 0.0736 - val_accuracy: 0.8733 - val_loss: 0.4275\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9911 - loss: 0.0331 - val_accuracy: 0.8705 - val_loss: 0.6089\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9956 - loss: 0.0162 - val_accuracy: 0.8701 - val_loss: 0.7416\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9984 - loss: 0.0072 - val_accuracy: 0.8688 - val_loss: 0.8452\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.0084 - val_accuracy: 0.8692 - val_loss: 0.9479\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.8719 - val_loss: 1.0894\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.8714 - val_loss: 1.0995\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.8702 - val_loss: 1.1646\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.4588e-04 - val_accuracy: 0.8702 - val_loss: 1.2437\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.6490e-05 - val_accuracy: 0.8704 - val_loss: 1.2803\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.9946e-05 - val_accuracy: 0.8708 - val_loss: 1.3048\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.6517e-05 - val_accuracy: 0.8704 - val_loss: 1.3240\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.4283e-05 - val_accuracy: 0.8706 - val_loss: 1.3357\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.3139e-05 - val_accuracy: 0.8704 - val_loss: 1.3484\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.0445e-05 - val_accuracy: 0.8705 - val_loss: 1.3592\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 9.3348e-06 - val_accuracy: 0.8706 - val_loss: 1.3680\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 8.3641e-06 - val_accuracy: 0.8706 - val_loss: 1.3767\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.6204e-06 - val_accuracy: 0.8706 - val_loss: 1.3839\n",
            "Epoch 20/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.0560e-06 - val_accuracy: 0.8706 - val_loss: 1.3921\n",
            "CPU times: user 3min 48s, sys: 24.3 s, total: 4min 13s\n",
            "Wall time: 3min 35s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "history2 = network2.fit(X_imdb_train_,\n",
        "                      Y_imdb_train_,\n",
        "                      epochs=20,\n",
        "                      verbose=1,\n",
        "                      batch_size=100,\n",
        "                      validation_data=(X_imdb_test_, Y_imdb_test_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nWfmH7IDIiq"
      },
      "source": [
        "### Evaluating the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "outputId": "9bfba72a-2862-40e8-c7c4-a016ed3828cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OjAJcCbDIiq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 1.4145\n",
            "Test loss is 1.39\n",
            "Test accuracy is 87.1%\n"
          ]
        }
      ],
      "source": [
        "test_loss2, test_accuracy2 = network2.evaluate(X_imdb_test_, Y_imdb_test_)\n",
        "print(f'Test loss is {test_loss2:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy2:0.1%}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "outputId": "270d6bd1-59d1-4d16-98a7-917d597a2745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj5jDjA7DIiq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.9618e-06\n",
            "Train loss is 6.96e-06\n",
            "Train accuracy is 100.0%\n"
          ]
        }
      ],
      "source": [
        "train_loss2, train_accuracy2 = network2.evaluate(X_imdb_train_, Y_imdb_train_)\n",
        "print(f'Train loss is {train_loss2:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8urwFe_QDIiq"
      },
      "source": [
        "### Reducing Overfitting with Weight Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "outputId": "37438620-07dc-4761-815d-253472752f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQK-PSbqDIiq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.7835 - loss: 0.8489 - val_accuracy: 0.8703 - val_loss: 0.4220\n",
            "Epoch 2/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8741 - loss: 0.4153 - val_accuracy: 0.8454 - val_loss: 0.4550\n",
            "Epoch 3/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.8774 - loss: 0.3911 - val_accuracy: 0.8720 - val_loss: 0.3940\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8693 - loss: 0.3972\n",
            "Test loss is 0.394\n",
            "Test accuracy is 87.2%\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9147 - loss: 0.3219\n",
            "Train loss is 0.324\n",
            "Train accuracy is 91.2%\n"
          ]
        }
      ],
      "source": [
        "from keras import regularizers\n",
        "\n",
        "# Defining network architecture\n",
        "network2a = models.Sequential()\n",
        "network2a.add(layers.Input(shape=(number_of_features,)))\n",
        "network2a.add(layers.Dense(units=100,activation=\"relu\",\n",
        "                          kernel_regularizer=regularizers.l2(0.01),))\n",
        "network2a.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2a.add(layers.Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the Network\n",
        "network2a.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the network\n",
        "history2a = network2a.fit(X_imdb_train_, Y_imdb_train_, epochs=3, verbose=1, batch_size=100,\n",
        "                      validation_data=(X_imdb_test_, Y_imdb_test_))\n",
        "\n",
        "# Evaluating the model\n",
        "test_loss2a, test_accuracy2a = network2a.evaluate(X_imdb_test_, Y_imdb_test_)\n",
        "print(f'Test loss is {test_loss2a:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy2a:0.1%}')\n",
        "train_loss2a, train_accuracy2a = network2a.evaluate(X_imdb_train_, Y_imdb_train_)\n",
        "print(f'Train loss is {train_loss2a:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2a:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4nq11n3DIiq"
      },
      "source": [
        "### Reducing Overfitting with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "outputId": "71f21d49-c45d-4bb0-9b0e-fb39bf0df816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh9b0CX4DIir"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.8113 - loss: 0.4225 - val_accuracy: 0.8831 - val_loss: 0.2802\n",
            "Epoch 2/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 33ms/step - accuracy: 0.9307 - loss: 0.1913 - val_accuracy: 0.8814 - val_loss: 0.2993\n",
            "Epoch 3/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.9526 - loss: 0.1311 - val_accuracy: 0.8768 - val_loss: 0.3467\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8738 - loss: 0.3521\n",
            "Test loss is 0.347\n",
            "Test accuracy is 87.7%\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0737\n",
            "Train loss is 0.0736\n",
            "Train accuracy is 97.9%\n"
          ]
        }
      ],
      "source": [
        "from keras import regularizers\n",
        "\n",
        "# Defining network architecture\n",
        "network2b = models.Sequential()\n",
        "network2b.add(layers.Input(shape=(number_of_features,)))\n",
        "network2b.add(layers.Dense(units=100,activation=\"relu\"))\n",
        "network2b.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2b.add(layers.Dropout(0.2))\n",
        "network2b.add(layers.Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the Network\n",
        "network2b.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the network\n",
        "history2b = network2b.fit(X_imdb_train_, Y_imdb_train_, epochs=3, verbose=1, batch_size=100,\n",
        "                      validation_data=(X_imdb_test_, Y_imdb_test_))\n",
        "\n",
        "# Evaluating the model\n",
        "test_loss2b, test_accuracy2b = network2b.evaluate(X_imdb_test_, Y_imdb_test_)\n",
        "print(f'Test loss is {test_loss2b:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy2b:0.1%}')\n",
        "train_loss2b, train_accuracy2b = network2b.evaluate(X_imdb_train_, Y_imdb_train_)\n",
        "print(f'Train loss is {train_loss2b:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2b:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5fRMRa9DIir"
      },
      "source": [
        "### Reducing Overfitting with Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "outputId": "2ccba99d-2ead-48a0-d870-a419dad368a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjB-WSFCDIir"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8031 - loss: 0.4220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.8033 - loss: 0.4217 - val_accuracy: 0.8800 - val_loss: 0.2909\n",
            "Epoch 2/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 32ms/step - accuracy: 0.9261 - loss: 0.1971 - val_accuracy: 0.8712 - val_loss: 0.3258\n",
            "Epoch 3/3\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9532 - loss: 0.1308 - val_accuracy: 0.8715 - val_loss: 0.3547\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3566\n",
            "Test accuracy is 87.2%\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.0763\n",
            "Train loss is 0.0765\n",
            "Train accuracy is 97.8%\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import keras\n",
        "\n",
        "number_of_features = 10000\n",
        "\n",
        "# Defining network architecture\n",
        "network2c = models.Sequential()\n",
        "network2c.add(layers.Input(shape=(number_of_features,)))\n",
        "network2c.add(layers.Dense(units=100,activation=\"relu\"))\n",
        "network2c.add(layers.Dense(units=100, activation=\"relu\"))\n",
        "network2c.add(layers.Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "# Compiling the Network\n",
        "network2c.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Set callback functions to early stop training and save the best model so far\n",
        "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2),\n",
        "             ModelCheckpoint(filepath=\"best_model.h5\", monitor=\"val_loss\", save_best_only=True)]\n",
        "# EarlyStopping stops training early if the model stops improving on the validation set.\n",
        "# If the validation loss doesn't improve for 2 consecutive epochs (patience), training is stopped.\n",
        "# ModelCheckpoint saves the model during training in an HDF5 format file called \"best_model.h5\".\n",
        "# Only saves the model if the validation loss improves (i.e., is lower than the previous best).\n",
        "\n",
        "# Training the network\n",
        "history2c = network2c.fit(X_imdb_train_, Y_imdb_train_, epochs=3, verbose=1, batch_size=100,\n",
        "                          callbacks=callbacks, # Early stopping\n",
        "                          validation_data=(X_imdb_test_, Y_imdb_test_))\n",
        "\n",
        "# Evaluating the model\n",
        "test_loss2c, test_accuracy2c = network2c.evaluate(X_imdb_test_, Y_imdb_test_)\n",
        "print(f'Test accuracy is {test_accuracy2c:0.1%}')\n",
        "train_loss2c, train_accuracy2c = network2c.evaluate(X_imdb_train_, Y_imdb_train_)\n",
        "print(f'Train loss is {train_loss2c:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy2c:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. Reuter's dataset"
      ],
      "metadata": {
        "id": "RZ8jYphH7BRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.datasets import reuters\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "number_of_features = 5000\n",
        "(X_reuters_train, Y_reuters_train), (X_reuters_test, Y_reuters_test) = reuters.load_data(num_words=number_of_features)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\n",
        "X_reuters_train_ = tokenizer.sequences_to_matrix(X_reuters_train, mode=\"binary\")\n",
        "X_reuters_test_ = tokenizer.sequences_to_matrix(X_reuters_test,mode=\"binary\")"
      ],
      "metadata": {
        "id": "vwL8h-39HbEA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Bxv0E8qd-Sla"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rf_reuters = RandomForestClassifier()\n",
        "rf_reuters.fit(X_reuters_train_, Y_reuters_train)\n",
        "print(\"\\nRandom Forest Classifier\")\n",
        "print(classification_report(Y_reuters_test, rf_reuters.predict(X_reuters_test_)))\n",
        "\n",
        "svm_reuters = SVC()\n",
        "svm_reuters.fit(X_reuters_train_, Y_reuters_train)\n",
        "print(\"\\nSupport Vector Machine\")\n",
        "print(classification_report(Y_reuters_test, svm_reuters.predict(X_reuters_test_)))\n",
        "\n",
        "lr_reuters = LogisticRegression()\n",
        "lr_reuters.fit(X_reuters_train_, Y_reuters_train)\n",
        "print(\"\\nLogistic Regression\")\n",
        "print(classification_report(Y_reuters_test, lr_reuters.predict(X_reuters_test_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv1y1CSs9p91",
        "outputId": "5fdf71be-09db-4a98-bc50-2c54c6557a42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.50      0.63        12\n",
            "           1       0.58      0.78      0.66       105\n",
            "           2       0.85      0.55      0.67        20\n",
            "           3       0.92      0.91      0.91       813\n",
            "           4       0.69      0.91      0.78       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       1.00      0.79      0.88        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.76      0.74      0.75        38\n",
            "           9       0.81      0.68      0.74        25\n",
            "          10       0.88      0.73      0.80        30\n",
            "          11       0.59      0.78      0.67        83\n",
            "          12       0.50      0.15      0.24        13\n",
            "          13       0.65      0.41      0.50        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       1.00      0.11      0.20         9\n",
            "          16       0.65      0.76      0.70        99\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.62      0.50      0.56        20\n",
            "          19       0.65      0.81      0.72       133\n",
            "          20       0.78      0.36      0.49        70\n",
            "          21       0.81      0.63      0.71        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.40      0.17      0.24        12\n",
            "          24       0.50      0.11      0.17        19\n",
            "          25       0.87      0.42      0.57        31\n",
            "          26       1.00      0.12      0.22         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.50      0.10      0.17        10\n",
            "          29       0.40      0.50      0.44         4\n",
            "          30       0.75      0.25      0.38        12\n",
            "          31       0.50      0.08      0.13        13\n",
            "          32       1.00      0.20      0.33        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       1.00      0.43      0.60         7\n",
            "          35       1.00      0.17      0.29         6\n",
            "          36       0.50      0.09      0.15        11\n",
            "          37       1.00      0.50      0.67         2\n",
            "          38       0.00      0.00      0.00         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       1.00      0.20      0.33        10\n",
            "          41       0.00      0.00      0.00         8\n",
            "          42       1.00      0.33      0.50         3\n",
            "          43       0.83      0.83      0.83         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.76      2246\n",
            "   macro avg       0.67      0.41      0.46      2246\n",
            "weighted avg       0.76      0.76      0.74      2246\n",
            "\n",
            "\n",
            "Support Vector Machine\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.50      0.60        12\n",
            "           1       0.54      0.82      0.65       105\n",
            "           2       0.90      0.45      0.60        20\n",
            "           3       0.92      0.94      0.93       813\n",
            "           4       0.73      0.92      0.81       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       1.00      0.36      0.53        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.78      0.66      0.71        38\n",
            "           9       1.00      0.56      0.72        25\n",
            "          10       0.91      0.70      0.79        30\n",
            "          11       0.57      0.81      0.67        83\n",
            "          12       0.50      0.15      0.24        13\n",
            "          13       0.58      0.51      0.54        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.00      0.00      0.00         9\n",
            "          16       0.61      0.78      0.68        99\n",
            "          17       0.00      0.00      0.00        12\n",
            "          18       0.65      0.55      0.59        20\n",
            "          19       0.65      0.81      0.72       133\n",
            "          20       0.77      0.34      0.48        70\n",
            "          21       0.81      0.63      0.71        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.00      0.00      0.00        12\n",
            "          24       0.50      0.11      0.17        19\n",
            "          25       0.94      0.48      0.64        31\n",
            "          26       0.00      0.00      0.00         8\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.00      0.00      0.00        10\n",
            "          29       0.00      0.00      0.00         4\n",
            "          30       0.80      0.33      0.47        12\n",
            "          31       0.00      0.00      0.00        13\n",
            "          32       1.00      0.10      0.18        10\n",
            "          33       1.00      0.80      0.89         5\n",
            "          34       1.00      0.43      0.60         7\n",
            "          35       1.00      0.17      0.29         6\n",
            "          36       0.50      0.09      0.15        11\n",
            "          37       0.00      0.00      0.00         2\n",
            "          38       0.00      0.00      0.00         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.00      0.00      0.00        10\n",
            "          41       0.50      0.12      0.20         8\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       1.00      0.33      0.50         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.77      2246\n",
            "   macro avg       0.52      0.34      0.38      2246\n",
            "weighted avg       0.75      0.77      0.74      2246\n",
            "\n",
            "\n",
            "Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.76        12\n",
            "           1       0.69      0.78      0.74       105\n",
            "           2       0.71      0.75      0.73        20\n",
            "           3       0.91      0.93      0.92       813\n",
            "           4       0.79      0.87      0.83       474\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.87      0.93      0.90        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.67      0.74      0.70        38\n",
            "           9       0.82      0.72      0.77        25\n",
            "          10       0.87      0.90      0.89        30\n",
            "          11       0.60      0.73      0.66        83\n",
            "          12       0.33      0.15      0.21        13\n",
            "          13       0.57      0.65      0.61        37\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.50      0.11      0.18         9\n",
            "          16       0.68      0.74      0.71        99\n",
            "          17       1.00      0.50      0.67        12\n",
            "          18       0.85      0.55      0.67        20\n",
            "          19       0.67      0.72      0.70       133\n",
            "          20       0.53      0.46      0.49        70\n",
            "          21       0.63      0.70      0.67        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.57      0.33      0.42        12\n",
            "          24       0.60      0.32      0.41        19\n",
            "          25       0.88      0.68      0.76        31\n",
            "          26       1.00      0.62      0.77         8\n",
            "          27       1.00      0.25      0.40         4\n",
            "          28       0.50      0.30      0.38        10\n",
            "          29       0.50      0.75      0.60         4\n",
            "          30       0.83      0.42      0.56        12\n",
            "          31       0.71      0.38      0.50        13\n",
            "          32       1.00      0.80      0.89        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       1.00      0.57      0.73         7\n",
            "          35       1.00      0.33      0.50         6\n",
            "          36       0.50      0.27      0.35        11\n",
            "          37       1.00      0.50      0.67         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.75      0.30      0.43        10\n",
            "          41       0.50      0.12      0.20         8\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.75      1.00      0.86         6\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.79      2246\n",
            "   macro avg       0.68      0.52      0.56      2246\n",
            "weighted avg       0.78      0.79      0.78      2246\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3."
      ],
      "metadata": {
        "id": "eN78hda8DKyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iris without regularisation"
      ],
      "metadata": {
        "id": "dQphTCctNXmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from keras import regularizers\n",
        "import pandas as pd\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "iris_X = iris.data.features\n",
        "iris_y = iris.data.targets\n",
        "\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(iris_X, iris_y, test_size=0.2, random_state=42)\n",
        "y_train_iris = y_train_iris.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
        "y_test_iris = y_test_iris.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(X_train_iris.shape[1], )))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden1'))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden2'))\n",
        "network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "network.summary()\n",
        "\n",
        "history = network.fit(X_train_iris, y_train_iris, epochs=3, verbose=1, batch_size=10,\n",
        "                      validation_data=(X_test_iris, y_test_iris))\n",
        "test_loss, test_accuracy = network.evaluate(X_test_iris, y_test_iris)\n",
        "print(f'Test loss is {test_loss:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy:0.1%}')\n",
        "train_loss, train_accuracy = network.evaluate(X_train_iris, y_train_iris)\n",
        "print(f'Train loss is {train_loss:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy:0.1%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "2gzQXrMZ9z1o",
        "outputId": "05bc5dbe-9b68-418f-9925-abbeafede60e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ff2a4110b0a8>:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_train_iris = y_train_iris.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
            "<ipython-input-6-ff2a4110b0a8>:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_test_iris = y_test_iris.replace({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_64\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_64\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m1_hidden1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m1_hidden2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m1_hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m1_hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19\u001b[0m (76.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (76.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19\u001b[0m (76.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (76.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (10, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(10, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3340 - loss: 0.0000e+00 - val_accuracy: 0.3000 - val_loss: 0.0000e+00\n",
            "Epoch 2/3\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3000 - loss: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (10, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(10, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3475 - loss: 0.0000e+00 - val_accuracy: 0.3000 - val_loss: 0.0000e+00\n",
            "Epoch 3/3\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3708 - loss: 0.0000e+00 - val_accuracy: 0.3000 - val_loss: 0.0000e+00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.3000 - loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss is 0.0\n",
            "Test accuracy is 30.0%\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3388 - loss: 0.0000e+00 \n",
            "Train loss is 0.0\n",
            "Train accuracy is 34.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iris with regularisation"
      ],
      "metadata": {
        "id": "BzHiS6e0Nb8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(X_train_iris.shape[1], )))\n",
        "network.add(layers.Dense(units=2,activation=\"relu\",\n",
        "                          kernel_regularizer=regularizers.l2(0.1), name='m1_hidden1'))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden2'))\n",
        "network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "network.summary()\n",
        "\n",
        "history = network.fit(X_train_iris, y_train_iris, epochs=3, verbose=1, batch_size=10,\n",
        "                      validation_data=(X_test_iris, y_test_iris))\n",
        "test_loss, test_accuracy = network.evaluate(X_test_iris, y_test_iris)\n",
        "print(f'Test loss is {test_loss:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy:0.1%}')\n",
        "train_loss, train_accuracy = network.evaluate(X_train_iris, y_train_iris)\n",
        "print(f'Train loss is {train_loss:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy:0.1%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "uYAmHbPRKAcY",
        "outputId": "5c47970c-a4f8-4367-8bdc-5fc5ad0780b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_65\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_65\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m1_hidden1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m1_hidden2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m1_hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m1_hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19\u001b[0m (76.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (76.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19\u001b[0m (76.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (76.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (10, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(10, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3509 - loss: 0.1623 - val_accuracy: 0.3000 - val_loss: 0.1578\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (10, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(10, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3416 - loss: 0.1570 - val_accuracy: 0.3000 - val_loss: 0.1546\n",
            "Epoch 3/3\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3080 - loss: 0.1539 - val_accuracy: 0.3000 - val_loss: 0.1516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.3000 - loss: 0.1516\n",
            "Test loss is 0.152\n",
            "Test accuracy is 30.0%\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3388 - loss: 0.1516\n",
            "Train loss is 0.152\n",
            "Train accuracy is 34.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wine without regularisation"
      ],
      "metadata": {
        "id": "EWC5O7PfNfB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wine = fetch_ucirepo(id=109)\n",
        "\n",
        "wine_X = wine.data.features\n",
        "wine_y = wine.data.targets\n",
        "\n",
        "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(wine_X, wine_y, test_size=0.2, random_state=42)\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(X_train_wine.shape[1],)))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m2_hidden1'))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m2_hidden2'))\n",
        "network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "network.summary()\n",
        "\n",
        "history = network.fit(X_train_wine, y_train_wine, epochs=3, verbose=1, batch_size=10,\n",
        "                      validation_data=(X_test_wine, y_test_wine))\n",
        "test_loss, test_accuracy = network.evaluate(X_test_wine, y_test_wine)\n",
        "print(f'Test loss is {test_loss:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy:0.1%}')\n",
        "train_loss, train_accuracy = network.evaluate(X_train_wine, y_train_wine)\n",
        "print(f'Train loss is {train_loss:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy:0.1%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "Es6ucIkmEB-O",
        "outputId": "44e36157-0468-43d5-d312-374eed867319"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_66\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_66\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m2_hidden1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m28\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m2_hidden2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m2_hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m2_hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37\u001b[0m (148.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> (148.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37\u001b[0m (148.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> (148.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.3194 - loss: 0.0000e+00 - val_accuracy: 0.3889 - val_loss: 0.0000e+00\n",
            "Epoch 2/3\n",
            "\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3142 - loss: 0.0000e+00 - val_accuracy: 0.3889 - val_loss: 0.0000e+00\n",
            "Epoch 3/3\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3362 - loss: 0.0000e+00 - val_accuracy: 0.3889 - val_loss: 0.0000e+00\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3738 - loss: 0.0000e+00\n",
            "Test loss is 0.0\n",
            "Test accuracy is 38.9%\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3222 - loss: 0.0000e+00 \n",
            "Train loss is 0.0\n",
            "Train accuracy is 31.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wine with regularisation"
      ],
      "metadata": {
        "id": "qbCJhtzpNhVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(X_train_wine.shape[1],)))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m2_hidden1'))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\",kernel_regularizer=regularizers.l2(0.1),\n",
        "                         name='m2_hidden2'))\n",
        "network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "network.summary()\n",
        "\n",
        "history = network.fit(X_train_wine, y_train_wine, epochs=3, verbose=1, batch_size=10,\n",
        "                      validation_data=(X_test_wine, y_test_wine))\n",
        "test_loss, test_accuracy = network.evaluate(X_test_wine, y_test_wine)\n",
        "print(f'Test loss is {test_loss:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy:0.1%}')\n",
        "train_loss, train_accuracy = network.evaluate(X_train_wine, y_train_wine)\n",
        "print(f'Train loss is {train_loss:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy:0.1%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "1K7PNZOVKX0A",
        "outputId": "f737fcc7-9253-4fa2-be8a-3f71344dba87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_67\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_67\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m2_hidden1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m28\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m2_hidden2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m2_hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m2_hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37\u001b[0m (148.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> (148.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37\u001b[0m (148.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> (148.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.3102 - loss: 0.1287 - val_accuracy: 0.3889 - val_loss: 0.1228\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2959 - loss: 0.1213 - val_accuracy: 0.3889 - val_loss: 0.1170\n",
            "Epoch 3/3\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2944 - loss: 0.1156 - val_accuracy: 0.3889 - val_loss: 0.1116\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3738 - loss: 0.1116\n",
            "Test loss is 0.112\n",
            "Test accuracy is 38.9%\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3222 - loss: 0.1116 \n",
            "Train loss is 0.112\n",
            "Train accuracy is 31.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4."
      ],
      "metadata": {
        "id": "6VvT26GhNw2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iris early stopping"
      ],
      "metadata": {
        "id": "htACS7xYNy5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(X_train_iris.shape[1], )))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden1'))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden2'))\n",
        "network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "network.summary()\n",
        "\n",
        "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2),\n",
        "             ModelCheckpoint(filepath=\"best_model.h5\", monitor=\"val_loss\", save_best_only=True)]\n",
        "\n",
        "history = network.fit(X_train_iris, y_train_iris, epochs=3, verbose=1, batch_size=10,\n",
        "                      callbacks=callbacks, validation_data=(X_test_iris, y_test_iris))\n",
        "test_loss, test_accuracy = network.evaluate(X_test_iris, y_test_iris)\n",
        "print(f'Test loss is {test_loss:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy:0.1%}')\n",
        "train_loss, train_accuracy = network.evaluate(X_train_iris, y_train_iris)\n",
        "print(f'Train loss is {train_loss:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy:0.1%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "zwJVZTibKqXq",
        "outputId": "93dc931a-e85a-483f-c970-eee122d98997"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_68\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_68\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m1_hidden1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m1_hidden2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m1_hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m1_hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19\u001b[0m (76.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (76.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19\u001b[0m (76.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> (76.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (10, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(10, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 784ms/step - accuracy: 0.4000 - loss: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (10, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(10, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3408 - loss: 0.0000e+00 - val_accuracy: 0.3000 - val_loss: 0.0000e+00\n",
            "Epoch 2/3\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3060 - loss: 0.0000e+00 - val_accuracy: 0.3000 - val_loss: 0.0000e+00\n",
            "Epoch 3/3\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3893 - loss: 0.0000e+00 - val_accuracy: 0.3000 - val_loss: 0.0000e+00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.3000 - loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss is 0.0\n",
            "Test accuracy is 30.0%\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3388 - loss: 0.0000e+00 \n",
            "Train loss is 0.0\n",
            "Train accuracy is 34.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wine early stopping"
      ],
      "metadata": {
        "id": "41c856dLOcyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(X_train_wine.shape[1],)))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m2_hidden1'))\n",
        "network.add(layers.Dense(units=2, activation=\"relu\", name='m2_hidden2'))\n",
        "network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "network.summary()\n",
        "\n",
        "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2),\n",
        "             ModelCheckpoint(filepath=\"best_model.h5\", monitor=\"val_loss\", save_best_only=True)]\n",
        "\n",
        "history = network.fit(X_train_wine, y_train_wine, epochs=3, verbose=1, batch_size=10,\n",
        "                      callbacks=callbacks, validation_data=(X_test_wine, y_test_wine))\n",
        "test_loss, test_accuracy = network.evaluate(X_test_wine, y_test_wine)\n",
        "print(f'Test loss is {test_loss:0.3}')\n",
        "print(f'Test accuracy is {test_accuracy:0.1%}')\n",
        "train_loss, train_accuracy = network.evaluate(X_train_wine, y_train_wine)\n",
        "print(f'Train loss is {train_loss:0.3}')\n",
        "print(f'Train accuracy is {train_accuracy:0.1%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "-wM5hIBMOaNV",
        "outputId": "92895f2f-6894-4e06-f13a-ec675609370c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_69\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_69\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m2_hidden1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m28\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m2_hidden2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_197 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ m2_hidden1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ m2_hidden2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_197 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37\u001b[0m (148.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> (148.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37\u001b[0m (148.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> (148.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m 1/15\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 845ms/step - accuracy: 0.6000 - loss: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3549 - loss: 0.0000e+00 - val_accuracy: 0.3889 - val_loss: 0.0000e+00\n",
            "Epoch 2/3\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3235 - loss: 0.0000e+00 - val_accuracy: 0.3889 - val_loss: 0.0000e+00\n",
            "Epoch 3/3\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3351 - loss: 0.0000e+00 - val_accuracy: 0.3889 - val_loss: 0.0000e+00\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3738 - loss: 0.0000e+00\n",
            "Test loss is 0.0\n",
            "Test accuracy is 38.9%\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3222 - loss: 0.0000e+00 \n",
            "Train loss is 0.0\n",
            "Train accuracy is 31.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5."
      ],
      "metadata": {
        "id": "RQ0gKGS7Osm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid SearchCV Iris"
      ],
      "metadata": {
        "id": "G_SWuGP3OwXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def create_network(optimizer=\"rmsprop\"):\n",
        "    network = models.Sequential()\n",
        "    network.add(layers.Input(shape=(X_train_iris.shape[1], )))\n",
        "    network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden1'))\n",
        "    network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden2'))\n",
        "    network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "    network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "    return network\n",
        "\n",
        "neural_network = KerasClassifier(model=create_network, verbose=1)\n",
        "\n",
        "epochs = [5, 10]\n",
        "batches = [5, 10]\n",
        "optimizers = [\"rmsprop\", \"adam\"]\n",
        "\n",
        "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
        "\n",
        "grid = GridSearchCV(estimator=neural_network,\n",
        "                    param_grid=hyperparameters)\n",
        "\n",
        "grid_result = grid.fit(X_train_iris, y_train_iris)\n",
        "\n",
        "grid_result.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8e1-I2COpm-",
        "outputId": "d1f30d5f-ba14-4428-9bbd-f554764f0417"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3140 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3190 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3040 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2802 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2855 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3082 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3941 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4076 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3008 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4213 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3231 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3688 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3198 - loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3560 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3759 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3130 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3141 - loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3774 - loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3056 - loss: 0.0000e+00     \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3222 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2920 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4075 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3909 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2789 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3238 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3187 - loss: 0.0000e+00       \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3775 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3823 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2485 - loss: 0.0000e+00     \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3458 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3124 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3350 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3245 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2712 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3716 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3063 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3219 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3083 - loss: 0.0000e+00     \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3679 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3600 - loss: 0.0000e+00     \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3807 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3392 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2788 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3982 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2727 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3668 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3792 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2637 - loss: 0.0000e+00     \n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2951 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3108 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2849 - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3331 - loss: 0.0000e+00  \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3787 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3225 - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3119 - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3501 - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3203 - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3123 - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3488 - loss: 0.0000e+00\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4195 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3248 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4215 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3140 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3264 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3580 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3610 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3266 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3847 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3127 - loss: 0.0000e+00     \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3580 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3595 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3832 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3623 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3552 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3966 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3717 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3041 - loss: 0.0000e+00     \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3742 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3645 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3093 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3549 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3243 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2941 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3456 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3144 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3038 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3650 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3492 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3628 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3115 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4014 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3897 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4053 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4140 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3524 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2945 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2823 - loss: 0.0000e+00     \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3507 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3938 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3144 - loss: 0.0000e+00       \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3515 - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3647 - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2642 - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3013 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3000 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3745 - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2671 - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4047 - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3038 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4084 - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3519 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3441 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3510 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3283 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3029 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3719 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3895 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3025 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3856 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3311 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3629 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3011 - loss: 0.0000e+00     \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2887 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3628 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3870 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3651 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3576 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4270 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3723 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2625 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2510 - loss: 0.0000e+00     \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4067 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3176 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4489 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3389 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4474 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4094 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3771 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3157 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3100 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3057 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3626 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3492 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3867 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3276 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3280 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3488 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4033 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3026 - loss: 0.0000e+00 \n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3165 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3053 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3311 - loss: 0.0000e+00  \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2821 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3546 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3698 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3119 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4183 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3271 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3874 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3156 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3596 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2971 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3299 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2845 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3571 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3507 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3566 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2701 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4022 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3691 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3833 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3228 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3162 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2918 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2662 - loss: 0.0000e+00    \n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2812 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3002 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2934 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2973 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3339 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3206 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4367 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3271 - loss: 0.0000e+00  \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3034 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2891 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3237 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3272 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3333 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3700 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3198 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3364 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3943 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3564 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2985 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2805 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3460 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4188 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3669 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3141 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3969 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3090 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3099 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2884 - loss: 0.0000e+00  \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3592 - loss: 0.0000e+00  \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3240 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3353 - loss: 0.0000e+00  \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3235 - loss: 0.0000e+00  \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3153 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3052 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3648 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3166 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3126 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3088 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3040 - loss: 0.0000e+00  \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3160 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3977 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3439 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2837 - loss: 0.0000e+00     \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3360 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3505 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3358 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3808 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3417 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2949 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3239 - loss: 0.0000e+00  \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3993 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2893 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3153 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3674 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2922 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2778 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3551 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3841 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2859 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3909 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3646 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3665 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3891 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3788 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3143 - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2831 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3430 - loss: 0.0000e+00  \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3731 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3734 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3329 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3630 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3424 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2801 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3620 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3559 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3225 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3801 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3373 - loss: 0.0000e+00  \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3169 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3116 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3751 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3172 - loss: 0.0000e+00  \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4036 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3443 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3763 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3955 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3218 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4152 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4153 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3368 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3026 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4135 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3888 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3609 - loss: 0.0000e+00  \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3532 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3314 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3766 - loss: 0.0000e+00  \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3480 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3870 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3559 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3675 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3883 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3415 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3151 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3455 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3920 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3757 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4182 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3337 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3655 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3785 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3640 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3489 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3250 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3705 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3071 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3208 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3168 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2726 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3644 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3203 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3145 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3271 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2595 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3352 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3197 - loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3220 - loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3169 - loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3246 - loss: 0.0000e+00 \n",
            "CPU times: user 1min 9s, sys: 3.43 s, total: 1min 12s\n",
            "Wall time: 1min 21s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 5, 'epochs': 5, 'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "def create_network(optimizer=\"rmsprop\"):\n",
        "    network = models.Sequential()\n",
        "    network.add(layers.Input(shape=(X_train_wine.shape[1], )))\n",
        "    network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden1'))\n",
        "    network.add(layers.Dense(units=2, activation=\"relu\", name='m1_hidden2'))\n",
        "    network.add(layers.Dense(units=1, activation=\"softmax\"))\n",
        "\n",
        "    network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "    return network\n",
        "\n",
        "neural_network = KerasClassifier(model=create_network, verbose=1)\n",
        "\n",
        "epochs = [5, 10]\n",
        "batches = [5, 10]\n",
        "optimizers = [\"rmsprop\", \"adam\"]\n",
        "\n",
        "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
        "\n",
        "grid = GridSearchCV(estimator=neural_network,\n",
        "                    param_grid=hyperparameters)\n",
        "\n",
        "grid_result = grid.fit(X_train_wine, y_train_wine)\n",
        "\n",
        "grid_result.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p4enDOiRhUa",
        "outputId": "2ef4a424-91bc-4ca6-8fff-fd363c0f5f27"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4124 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4030 - loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3758 - loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3374 - loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3962 - loss: 0.0000e+00\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3732 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3882 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3968 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5071 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4427 - loss: 0.0000e+00\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4023 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4335 - loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3587 - loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3883 - loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4368 - loss: 0.0000e+00\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3770 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4394 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3840 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4112 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3181 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4077 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3731 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4408 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4468 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4263 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3832 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2820 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3820 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3447 - loss: 0.0000e+00     \n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3487 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4524 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4736 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3467 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3578 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4166 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4353 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4590 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4232 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3683 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4345 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4562 - loss: 0.0000e+00   \n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4396 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3347 - loss: 0.0000e+00     \n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3500 - loss: 0.0000e+00     \n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4389 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4918 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3736 - loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4607 - loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3666 - loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4153 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3706 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3553 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3926 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4363 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3869 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3981 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3905 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4723 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4468 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4010 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3767 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4032 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5120 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4040 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4054 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4034 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4170 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4043 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4186 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4081 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4232 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4068 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3889 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4483 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3795 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4317 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3695 - loss: 0.0000e+00     \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4518 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4101 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4818 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3790 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3877 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4093 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3528 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4186 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4096 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4837 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4393 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3768 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4218 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3761 - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4478 - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4218 - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4662 - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3301 - loss: 0.0000e+00  \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4424 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4287 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4160 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3749 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3760 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3600 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4370 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3713 - loss: 0.0000e+00     \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3774 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4385 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3385 - loss: 0.0000e+00     \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4238 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3599 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3847 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3896 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3971 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3825 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3897 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4085 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3736 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3502 - loss: 0.0000e+00     \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4120 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4124 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3720 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4194 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4225 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3828 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2988 - loss: 0.0000e+00     \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3586 - loss: 0.0000e+00     \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4885 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4185 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3951 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4363 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3216 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3896 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4574 - loss: 0.0000e+00   \n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4384 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4278 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3657 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3969 - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4164 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4123 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4231 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4566 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3958 - loss: 0.0000e+00 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4059 - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4083 - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4509 - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3939 - loss: 0.0000e+00     \n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4423 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3859 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4116 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4750 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3743 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3471 - loss: 0.0000e+00     \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4314 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4372 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4013 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3853 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4989 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4371 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3802 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3456 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4859 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3299 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4039 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3816 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4228 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4011 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3546 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3746 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4055 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4347 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3869 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3939 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4057 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4068 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3643 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3839 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4964 - loss: 0.0000e+00  \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4773 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3056 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4316 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4450 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4050 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3819 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3743 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3705 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3353 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3622 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4634 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3773 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3597 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3613 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4630 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3704 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4039 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3805 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4086 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4257 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3946 - loss: 0.0000e+00  \n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4139 - loss: 0.0000e+00 \n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3960 - loss: 0.0000e+00 \n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3307 - loss: 0.0000e+00 \n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3560 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3327 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4263 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3826 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3894 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3736 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3962 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4102 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4094 - loss: 0.0000e+00  \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3931 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3409 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4136 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3815 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3687 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4112 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3832 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4179 - loss: 0.0000e+00  \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3565 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3643 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3659 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3880 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3865 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3427 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3799 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4201 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3467 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4394 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4253 - loss: 0.0000e+00  \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4144 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3917 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4521 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4601 - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4256 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3834 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4170 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3480 - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3334 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3318 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4037 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3996 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4280 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3749 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4480 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3562 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3851 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3633 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3957 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4383 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4160 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3975 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3585 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3557 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3561 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3819 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4021 - loss: 0.0000e+00  \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3492 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3862 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3440 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4093 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3679 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3983 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4573 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4055 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3830 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3741 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4069 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3801 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4107 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4233 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4193 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4385 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4770 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4018 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3997 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3818 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4309 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3209 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4029 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3892 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4270 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4485 - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4161 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4223 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4224 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3963 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3568 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3943 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4037 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3756 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3907 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3793 - loss: 0.0000e+00  \n",
            "Epoch 2/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3489 - loss: 0.0000e+00 \n",
            "Epoch 3/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3695 - loss: 0.0000e+00 \n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3786 - loss: 0.0000e+00 \n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4190 - loss: 0.0000e+00 \n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3687 - loss: 0.0000e+00 \n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4445 - loss: 0.0000e+00 \n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4101 - loss: 0.0000e+00 \n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3870 - loss: 0.0000e+00 \n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3874 - loss: 0.0000e+00 \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Epoch 1/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3753 - loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3335 - loss: 0.0000e+00     \n",
            "Epoch 3/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3483 - loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3964 - loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4009 - loss: 0.0000e+00 \n",
            "CPU times: user 1min 10s, sys: 3.63 s, total: 1min 14s\n",
            "Wall time: 1min 25s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 5, 'epochs': 5, 'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRWSl7vEaRKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5.\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "wave = fetch_ucirepo(id=107)\n",
        "\n",
        "wave_X = wave.data.features\n",
        "wave_y = wave.data.targets\n",
        "\n",
        "X_train_wave, X_test_wave, y_train_wave, y_test_wave = train_test_split(wave_X, wave_y, test_size=0.4, random_state=42)\n",
        "dt_wave = DecisionTreeRegressor().fit(X_train_wave, y_train_wave)\n",
        "y_pred_wave = dt_wave.predict(X_test_wave)\n",
        "\n",
        "print(\"Decision Tree Regressor\")\n",
        "print(\"R2 score:\", r2_score(y_test_wave, y_pred_wave))\n",
        "print(\"Mean squared error:\", mean_squared_error(y_test_wave, y_pred_wave))\n",
        "\n",
        "lr_wave = LinearRegression().fit(X_train_wave, y_train_wave)\n",
        "y_pred_wave = lr_wave.predict(X_test_wave)\n",
        "\n",
        "print(\"\\nLinear Regression\")\n",
        "print(\"R2 score:\", r2_score(y_test_wave, y_pred_wave))\n",
        "print(\"Mean squared error:\", mean_squared_error(y_test_wave, y_pred_wave))\n",
        "\n",
        "print(\"\\nMLP Regression\")\n",
        "network1 = models.Sequential()\n",
        "network1.add(layers.Input(shape=(X_train_wave.shape[1],)))\n",
        "network1.add(layers.Dense(units=16, activation=\"relu\", name='m1_hidden1'))\n",
        "network1.add(layers.Dense(units=16, activation=\"relu\",name='m1_hidden2'))\n",
        "network1.add(layers.Dense(units=1, name='m1_output'))\n",
        "network1.compile(loss=\"mse\",\n",
        "                optimizer=\"RMSprop\",\n",
        "                metrics=[\"mse\"])\n",
        "history = network1.fit(X_train_wave,\n",
        "                      y_train_wave,\n",
        "                      epochs=10,\n",
        "                      verbose=0,\n",
        "                      batch_size=100,\n",
        "                      validation_data=(X_test_wave, y_test_wave))\n",
        "test_loss1, test_mse1 = network1.evaluate(X_test_wave, y_test_wave)\n",
        "print(f'Test loss is {test_loss1:0.3}')\n",
        "print(f'Test MSE is {test_mse1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G-Pm5jFcUj4",
        "outputId": "3e3a48fc-9a93-4eee-fc88-ec90943cd62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor\n",
            "R2 score: 0.19993155307963617\n",
            "Mean squared error: 0.526\n",
            "\n",
            "Linear Regression\n",
            "R2 score: 0.4557906096413009\n",
            "Mean squared error: 0.35778706238263697\n",
            "\n",
            "MLP Regression\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2734 - mse: 0.2734\n",
            "Test loss is 0.284\n",
            "Test MSE is 0.28381869196891785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6."
      ],
      "metadata": {
        "id": "BQG2lOhIeQVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "\n",
        "path = kagglehub.dataset_download(\"shubhankartiwari/ram-prices\")\n",
        "ram = pd.read_csv(path + '/ram_price.csv')\n",
        "\n",
        "ram_X = ram[['date']]\n",
        "ram_y = ram[['price']]\n",
        "\n",
        "X_train_ram, X_test_ram, y_train_ram, y_test_ram = train_test_split(ram_X, ram_y, test_size=0.4, random_state=42)\n",
        "dt_ram = DecisionTreeRegressor().fit(X_train_ram, y_train_ram)\n",
        "y_pred_ram = dt_ram.predict(X_test_ram)\n",
        "\n",
        "print(\"Decision Tree Regressor\")\n",
        "print(\"R2 score:\", r2_score(y_test_ram, y_pred_ram))\n",
        "print(\"Mean squared error:\", mean_squared_error(y_test_ram, y_pred_ram))\n",
        "\n",
        "lr_ram = LinearRegression().fit(X_train_ram, y_train_ram)\n",
        "y_pred_ram = lr_ram.predict(X_test_ram)\n",
        "\n",
        "print(\"\\nLinear Regression\")\n",
        "print(\"R2 score:\", r2_score(y_test_ram, y_pred_ram))\n",
        "print(\"Mean squared error:\", mean_squared_error(y_test_ram, y_pred_ram))\n",
        "\n",
        "print(\"MLP Regression\")\n",
        "network2 = models.Sequential()\n",
        "network2.add(layers.Input(shape=(X_train_ram.shape[1],)))\n",
        "network2.add(layers.Dense(units=16, activation=\"relu\", name='m2_hidden1'))\n",
        "network2.add(layers.Dense(units=16, activation=\"relu\", name='m2_hidden2'))\n",
        "network2.add(layers.Dense(units=1, name='m2_output'))\n",
        "network2.compile(loss=\"mse\",\n",
        "                optimizer=\"RMSprop\",\n",
        "                metrics=[\"mse\"])\n",
        "history = network2.fit(X_train_ram,\n",
        "                      y_train_ram,\n",
        "                      epochs=10,\n",
        "                      verbose=0,\n",
        "                      batch_size=100,\n",
        "                      validation_data=(X_test_ram, y_test_ram))\n",
        "test_loss2, test_mse2 = network2.evaluate(X_test_ram, y_test_ram)\n",
        "print(f'Test loss is {test_loss2:0.3}')\n",
        "print(f'Test MSE is {test_mse2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-qOZT7B0muM",
        "outputId": "1491e50a-fc00-419e-b8b2-9b316cc8b848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor\n",
            "R2 score: 0.05558392172125837\n",
            "Mean squared error: 51493594243.03619\n",
            "\n",
            "Linear Regression\n",
            "R2 score: -1648.7834578037334\n",
            "Mean squared error: 89953233451776.27\n",
            "MLP Regression\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 60801417216.0000 - mse: 60801417216.0000\n",
            "Test loss is 5.54e+10\n",
            "Test MSE is 55440564224.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}